# Local Deep Researcher

Local Deep Researcher æ˜¯ä¸€ä¸ªå®Œå…¨æœ¬åœ°åŒ–çš„ç½‘ç»œç ”ç©¶åŠ©æ‰‹ï¼Œæ”¯æŒä½¿ç”¨ [Ollama](https://ollama.com/search) æˆ– [OpenAI](https://openai.com/) æ‰˜ç®¡çš„ä»»ä½• LLMã€‚è¯¥é¡¹ç›®æä¾›ä¸¤ç§ç ”ç©¶æ¨¡å¼ï¼š

## ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½

### 1. åŸºç¡€ç ”ç©¶æ¨¡å¼ (Deep Researcher)
- **æ™ºèƒ½æœç´¢**: è‡ªåŠ¨ç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢ï¼Œæ”¶é›†å’Œæ€»ç»“æœç´¢ç»“æœ
- **è¿­ä»£ç ”ç©¶**: åæ€æ‘˜è¦ï¼Œè¯†åˆ«çŸ¥è¯†ç¼ºå£ï¼Œç”Ÿæˆåç»­æŸ¥è¯¢
- **æ·±åº¦åˆ†æ**: é‡å¤ç”¨æˆ·å®šä¹‰æ¬¡æ•°çš„å¾ªç¯ï¼Œç¡®ä¿ç ”ç©¶å®Œæ•´æ€§
- **æœ¬åœ°åŒ–**: å®Œå…¨æœ¬åœ°è¿è¡Œï¼Œä¿æŠ¤æ•°æ®éšç§

### 2. ä¸»ç®¡æ¶æ„æ¨¡å¼ (Supervisory Architecture) â­ æ–°å¢
- **å¤šAgentåä½œ**: é‡‡ç”¨ä¸»ç®¡æ™ºèƒ½ä½“åè°ƒå¤šä¸ªä¸“ä¸šAgent
- **ä»»åŠ¡åˆ†è§£**: è‡ªåŠ¨å°†å¤æ‚ç ”ç©¶è¯·æ±‚åˆ†è§£ä¸ºå…·ä½“ä»»åŠ¡
- **æ™ºèƒ½åˆ†é…**: ç ”ç©¶Agentã€åˆ†æAgentã€ç»¼åˆAgentååŒå·¥ä½œ
- **çŠ¶æ€ç®¡ç†**: å®æ—¶è·Ÿè¸ªå„AgentçŠ¶æ€å’Œä»»åŠ¡è¿›åº¦

## ğŸ¯ é€‚ç”¨åœºæ™¯

**åŸºç¡€æ¨¡å¼**: é€‚åˆå¿«é€Ÿç ”ç©¶ã€ç®€å•ä¸»é¢˜åˆ†æ
**ä¸»ç®¡æ¶æ„æ¨¡å¼**: é€‚åˆå¤æ‚ç ”ç©¶ã€å¤šç»´åº¦åˆ†æã€æ·±åº¦æ´å¯Ÿæå–




## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®
```shell
git clone https://github.com/langchain-ai/local-deep-researcher.git
cd local-deep-researcher
```

### 2. ç¯å¢ƒé…ç½®
å¤åˆ¶ç¯å¢ƒé…ç½®æ–‡ä»¶å¹¶æ ¹æ®éœ€è¦ç¼–è¾‘ï¼š
```shell
cp .env.example .env
```

ç¯å¢ƒå˜é‡æ§åˆ¶æ¨¡å‹é€‰æ‹©ã€æœç´¢å·¥å…·å’Œå…¶ä»–é…ç½®è®¾ç½®ã€‚è¿è¡Œåº”ç”¨ç¨‹åºæ—¶ï¼Œè¿™äº›å€¼å°†é€šè¿‡ `python-dotenv` è‡ªåŠ¨åŠ è½½ã€‚

### 3. é€‰æ‹©ç ”ç©¶æ¨¡å¼

#### ğŸ”§ åŸºç¡€ç ”ç©¶æ¨¡å¼
é€‚åˆå¿«é€Ÿç ”ç©¶å’Œç®€å•ä¸»é¢˜åˆ†æï¼š
```bash
python -m Langgraph_deep_researcher --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" --out research_report.md
```

#### ğŸ—ï¸ ä¸»ç®¡æ¶æ„æ¨¡å¼ (æ¨è)
é€‚åˆå¤æ‚ç ”ç©¶å’Œæ·±åº¦åˆ†æï¼š
```bash
python -m Langgraph_deep_researcher.supervisory_cli "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"
```

### ä½¿ç”¨ Ollama é€‰æ‹©æœ¬åœ°æ¨¡å‹

1. ä» [è¿™é‡Œ](https://ollama.com/download) ä¸‹è½½ Ollama åº”ç”¨ã€‚

2. ä» [Ollama](https://ollama.com/search) æ‹‰å–æœ¬åœ° LLMã€‚ä»¥ [DeepSeek R1](https://ollama.com/library/deepseek-r1:8b) ä¸ºä¾‹ï¼š
```shell
ollama pull deepseek-r1:8b
```

3. å¯é€‰åœ°ï¼Œä½¿ç”¨ä»¥ä¸‹ Ollama é…ç½®è®¾ç½®æ›´æ–° `.env` æ–‡ä»¶ã€‚

* å¦‚æœè®¾ç½®äº†è¿™äº›å€¼ï¼Œå®ƒä»¬å°†ä¼˜å…ˆäº `configuration.py` ä¸­ `Configuration` ç±»è®¾ç½®çš„é»˜è®¤å€¼ã€‚
```shell
LLM_PROVIDER=ollama
OLLAMA_BASE_URL="http://localhost:11434" # Ollama æœåŠ¡ç«¯ç‚¹ï¼Œé»˜è®¤ä¸º `http://localhost:11434`
LOCAL_LLM=model # è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¦‚æœæœªè®¾ç½®åˆ™é»˜è®¤ä¸º `llama3`
```

### é€‰æ‹©æœç´¢å·¥å…·

é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†ä½¿ç”¨ [DuckDuckGo](https://duckduckgo.com/) è¿›è¡Œç½‘ç»œæœç´¢ï¼Œæ— éœ€ API å¯†é’¥ã€‚ä½†æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡å°† API å¯†é’¥æ·»åŠ åˆ°ç¯å¢ƒæ–‡ä»¶ä¸­æ¥ä½¿ç”¨ [SearXNG](https://docs.searxng.org/)ã€[Tavily](https://tavily.com/) æˆ– [Perplexity](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api)ã€‚å¯é€‰åœ°ï¼Œä½¿ç”¨ä»¥ä¸‹æœç´¢å·¥å…·é…ç½®å’Œ API å¯†é’¥æ›´æ–° `.env` æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®äº†è¿™äº›å€¼ï¼Œå®ƒä»¬å°†ä¼˜å…ˆäº `configuration.py` ä¸­ `Configuration` ç±»è®¾ç½®çš„é»˜è®¤å€¼ã€‚
```shell
SEARCH_API=xxx # è¦ä½¿ç”¨çš„æœç´¢ APIï¼Œå¦‚ `duckduckgo`ï¼ˆé»˜è®¤ï¼‰
TAVILY_API_KEY=xxx # è¦ä½¿ç”¨çš„ tavily API å¯†é’¥
PERPLEXITY_API_KEY=xxx # è¦ä½¿ç”¨çš„ perplexity API å¯†é’¥
MAX_WEB_RESEARCH_LOOPS=xxx # ç ”ç©¶å¾ªç¯æ­¥éª¤çš„æœ€å¤§æ•°é‡ï¼Œé»˜è®¤ä¸º `3`
FETCH_FULL_PAGE=xxx # è·å–å®Œæ•´é¡µé¢å†…å®¹ï¼ˆä½¿ç”¨ `duckduckgo` æ—¶ï¼‰ï¼Œé»˜è®¤ä¸º `true`
USE_TOOL_CALLING=xxx # ä½¿ç”¨å·¥å…·è°ƒç”¨è€Œä¸æ˜¯ JSON æ¨¡å¼ï¼Œé»˜è®¤ä¸º `false`
STRIP_THINKING_TOKENS=xxx # ä»æ¨¡å‹å“åº”ä¸­å»é™¤ <think> ä»¤ç‰Œï¼Œé»˜è®¤ä¸º `true`
```

### ä»ç»ˆç«¯è¿è¡Œ

#### Mac/Linux

1. ï¼ˆæ¨èï¼‰åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š
```bash
python -m venv .venv
source .venv/bin/activate
```

2. å®‰è£…ä¾èµ–å¹¶è¿è¡Œï¼š

```bash
# å®‰è£…ä¾èµ–
pip install -e .

# è¿è¡Œç ”ç©¶åŠ©æ‰‹
python -m Langgraph_deep_researcher --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" --out research_report.md
```

#### Windows

1. ï¼ˆæ¨èï¼‰åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

* å®‰è£… `Python 3.11`ï¼ˆå¹¶åœ¨å®‰è£…è¿‡ç¨‹ä¸­æ·»åŠ åˆ° PATHï¼‰ã€‚
* é‡å¯ç»ˆç«¯ä»¥ç¡®ä¿ Python å¯ç”¨ï¼Œç„¶ååˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

2. å®‰è£…ä¾èµ–å¹¶è¿è¡Œï¼š

```powershell
# å®‰è£…ä¾èµ–
pip install -e .

# è¿è¡Œç ”ç©¶åŠ©æ‰‹
python -m Langgraph_deep_researcher --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" --out research_report.md
```

### å‘½ä»¤è¡Œä½¿ç”¨

#### ğŸ”§ åŸºç¡€ç ”ç©¶æ¨¡å¼

```bash
python -m Langgraph_deep_researcher --topic "äººå·¥æ™ºèƒ½è¶‹åŠ¿" --out ai_trends.md --provider ollama --model llama3 --loops 5
```

**å¯ç”¨é€‰é¡¹ï¼š**
- `--topic`: ç ”ç©¶ä¸»é¢˜ï¼ˆå¿…éœ€ï¼‰
- `--out`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `--provider`: åœ¨ "ollama" æˆ– "openai" ä¹‹é—´é€‰æ‹©
- `--model`: æŒ‡å®šæ¨¡å‹åç§°ï¼ˆå¦‚ "llama3", "gpt-4"ï¼‰
- `--loops`: ç ”ç©¶è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰
- `--search`: è¦ä½¿ç”¨çš„æœç´¢ APIï¼ˆ"duckduckgo", "tavily", "perplexity", "searxng"ï¼‰
- `--tool-calling`: ä½¿ç”¨å·¥å…·è°ƒç”¨è€Œä¸æ˜¯ JSON æ¨¡å¼
- `--no-strip-think`: ä¸ä»æ¨¡å‹å“åº”ä¸­å»é™¤ <think> ä»¤ç‰Œ

#### ğŸ—ï¸ ä¸»ç®¡æ¶æ„æ¨¡å¼

```bash
python -m Langgraph_deep_researcher.supervisory_cli "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿" --out ai_report.md --provider openai --model gpt-4 --max-loops 5
```

**å¯ç”¨é€‰é¡¹ï¼š**
- `topic`: ç ”ç©¶ä¸»é¢˜ï¼ˆå¿…éœ€ï¼‰
- `--out`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šsupervisory_research_report.mdï¼‰
- `--provider`: LLM æä¾›å•†ï¼ˆollama, openaiï¼‰
- `--model`: æ¨¡å‹åç§°
- `--search-api`: æœç´¢å¼•æ“ï¼ˆduckduckgo, tavily, perplexity, searxngï¼‰
- `--max-loops`: æœ€å¤§ç ”ç©¶å¾ªç¯æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰
- `--verbose`: æ˜¾ç¤ºè¯¦ç»†è¾“å‡º

### æ¨¡å‹å…¼å®¹æ€§è¯´æ˜

é€‰æ‹©æœ¬åœ° LLM æ—¶ï¼ŒæŸäº›æ­¥éª¤ä½¿ç”¨ç»“æ„åŒ– JSON è¾“å‡ºã€‚ä¸€äº›æ¨¡å‹å¯èƒ½éš¾ä»¥æ»¡è¶³æ­¤è¦æ±‚ï¼ŒåŠ©æ‰‹å…·æœ‰å›é€€æœºåˆ¶æ¥å¤„ç†è¿™ç§æƒ…å†µã€‚ä¾‹å¦‚ï¼Œ[DeepSeek R1 (7B)](https://ollama.com/library/deepseek-llm:7b) å’Œ [DeepSeek R1 (1.5B)](https://ollama.com/library/deepseek-r1:1.5b) æ¨¡å‹éš¾ä»¥ç”Ÿæˆæ‰€éœ€çš„ JSON è¾“å‡ºï¼ŒåŠ©æ‰‹å°†ä½¿ç”¨å›é€€æœºåˆ¶æ¥å¤„ç†è¿™ç§æƒ…å†µã€‚

å¯¹äºè¿™äº›æ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨ `--tool-calling` é€‰é¡¹æ¥å¯ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼ï¼Œè¿™é€šå¸¸æ¯” JSON æ¨¡å¼æ›´å¯é ã€‚
  

## å·¥ä½œåŸç†

### ğŸ”§ åŸºç¡€ç ”ç©¶æ¨¡å¼

Local Deep Researcher å—åˆ° [IterDRAG](https://arxiv.org/html/2410.04343v1#:~:text=To%20tackle%20this%20issue%2C%20we,used%20to%20generate%20intermediate%20answers.) çš„å¯å‘ã€‚è¿™ç§æ–¹æ³•å°†æŸ¥è¯¢åˆ†è§£ä¸ºå­æŸ¥è¯¢ï¼Œä¸ºæ¯ä¸ªå­æŸ¥è¯¢æ£€ç´¢æ–‡æ¡£ï¼Œå›ç­”å­æŸ¥è¯¢ï¼Œç„¶åé€šè¿‡ä¸ºç¬¬äºŒä¸ªå­æŸ¥è¯¢æ£€ç´¢æ–‡æ¡£æ¥æ„å»ºç­”æ¡ˆã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åšç±»ä¼¼çš„äº‹æƒ…ï¼š

1. **ç”Ÿæˆæœç´¢æŸ¥è¯¢** - ç»™å®šç”¨æˆ·æä¾›çš„ä¸»é¢˜ï¼Œä½¿ç”¨æœ¬åœ° LLMï¼ˆé€šè¿‡ [Ollama](https://ollama.com/search) æˆ– [OpenAI](https://openai.com/)ï¼‰ç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢
2. **æ‰§è¡Œç½‘ç»œæœç´¢** - ä½¿ç”¨æœç´¢å¼•æ“/å·¥å…·æ‰¾åˆ°ç›¸å…³æ¥æº
3. **æ€»ç»“å‘ç°** - ä½¿ç”¨ LLM æ€»ç»“ä¸ç”¨æˆ·æä¾›çš„ç ”ç©¶ä¸»é¢˜ç›¸å…³çš„ç½‘ç»œæœç´¢ç»“æœ
4. **åæ€æ‘˜è¦** - ç„¶åä½¿ç”¨ LLM åæ€æ‘˜è¦ï¼Œè¯†åˆ«çŸ¥è¯†ç¼ºå£
5. **ç”Ÿæˆåç»­æŸ¥è¯¢** - ç”Ÿæˆæ–°çš„æœç´¢æŸ¥è¯¢æ¥è§£å†³çŸ¥è¯†ç¼ºå£
6. **è¿­ä»£æ›´æ–°** - è¿‡ç¨‹é‡å¤ï¼Œæ‘˜è¦é€šè¿‡æ¥è‡ªç½‘ç»œæœç´¢çš„æ–°ä¿¡æ¯è¿›è¡Œè¿­ä»£æ›´æ–°
7. **å¯é…ç½®å¾ªç¯** - è¿è¡Œå¯é…ç½®æ¬¡æ•°çš„è¿­ä»£ï¼ˆå‚è§é…ç½®éƒ¨åˆ†ï¼‰

### ğŸ—ï¸ ä¸»ç®¡æ¶æ„æ¨¡å¼

ä¸»ç®¡æ¶æ„ç³»ç»Ÿé‡‡ç”¨å¤š Agent åä½œæ¨¡å¼ï¼Œå°†åŸæœ‰çš„ Deep Researcher ä½œä¸ºå­ Agentï¼Œç”±ä¸»ç®¡æ™ºèƒ½ä½“ç»Ÿä¸€åè°ƒç®¡ç†ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ä¸»ç®¡æ™ºèƒ½ä½“                  â”‚
â”‚    (Supervisory Agent)              â”‚
â”‚  â€¢ ä»»åŠ¡åˆ†è§£                          â”‚
â”‚  â€¢ ä»»åŠ¡åˆ†é…                          â”‚
â”‚  â€¢ è¿›åº¦åè°ƒ                          â”‚
â”‚  â€¢ ç»“æœæ•´åˆ                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”           â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚ç ”ç©¶Agentâ”‚           â”‚åˆ†æAgentâ”‚
â”‚(Deep    â”‚           â”‚(Analysisâ”‚
â”‚Researcher)â”‚         â”‚Agent)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ç»¼åˆAgent  â”‚
        â”‚(Synthesis â”‚
        â”‚Agent)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å·¥ä½œæµç¨‹ï¼š**
1. **ä»»åŠ¡åˆ†è§£é˜¶æ®µ** - ä¸»ç®¡æ™ºèƒ½ä½“åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œå°†å¤æ‚è¯·æ±‚åˆ†è§£ä¸ºå…·ä½“ä»»åŠ¡
2. **ç ”ç©¶æ‰§è¡Œé˜¶æ®µ** - ç ”ç©¶ Agent æ‰§è¡Œæ·±åº¦ç½‘ç»œç ”ç©¶ï¼Œæ”¶é›†å’Œæ•´ç†ç›¸å…³ä¿¡æ¯
3. **åˆ†æå¤„ç†é˜¶æ®µ** - åˆ†æ Agent å¯¹ç ”ç©¶ç»“æœè¿›è¡Œæ·±åº¦åˆ†æï¼Œæå–å…³é”®æ´å¯Ÿ
4. **ç»¼åˆæŠ¥å‘Šé˜¶æ®µ** - ç»¼åˆ Agent æ•´åˆæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆç»“æ„åŒ–çš„æœ€ç»ˆæŠ¥å‘Š

## è¾“å‡ºç»“æœ

ç ”ç©¶åŠ©æ‰‹ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„ç»¼åˆ Markdown æŠ¥å‘Šï¼š

- **ç ”ç©¶æ‘˜è¦**ï¼šå¯¹æ‚¨ä¸»é¢˜çš„è¯¦ç»†åˆ†æ
- **ä¿¡æ¯æ¥æº**ï¼šç ”ç©¶ä¸­ä½¿ç”¨çš„æ‰€æœ‰ç½‘ç»œæ¥æºï¼Œå¸¦æœ‰é€‚å½“çš„å¼•ç”¨
- **ç ”ç©¶è¿‡ç¨‹**ï¼šæœ‰å…³ä½¿ç”¨çš„è¿­ä»£ç ”ç©¶æ–¹æ³•çš„ä¿¡æ¯

æœ€ç»ˆæŠ¥å‘Šä¿å­˜ä¸º Markdown æ–‡ä»¶ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹ã€å…±äº«æˆ–è¿›ä¸€æ­¥å¤„ç†ã€‚


## ä½œä¸º Docker å®¹å™¨è¿è¡Œ

åŒ…å«çš„ `Dockerfile` å°†ç ”ç©¶åŠ©æ‰‹ä½œä¸ºå‘½ä»¤è¡Œå·¥å…·è¿è¡Œã€‚æ‚¨å¿…é¡»å•ç‹¬è¿è¡Œ Ollama å¹¶é…ç½® `OLLAMA_BASE_URL` ç¯å¢ƒå˜é‡ã€‚æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡æä¾› `LOCAL_LLM` ç¯å¢ƒå˜é‡æ¥æŒ‡å®šè¦ä½¿ç”¨çš„ Ollama æ¨¡å‹ã€‚

### åŸºç¡€ Docker ä½¿ç”¨

å…‹éš†ä»“åº“å¹¶æ„å»ºé•œåƒï¼š
```bash
$ docker build -t local-deep-researcher .
```

ä½¿ç”¨ç ”ç©¶ä¸»é¢˜è¿è¡Œå®¹å™¨ï¼š
```bash
$ docker run --rm -it \
  -e LLM_PROVIDER=ollama \
  -e OLLAMA_BASE_URL="http://host.docker.internal:11434/" \
  -e LOCAL_LLM="llama3" \
  -v $(pwd)/output:/app/output \
  local-deep-researcher \
  --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" \
  --out "/app/output/research_report.md"
```

### ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

é¡¹ç›®åŒ…å« `docker-compose.yml` æ–‡ä»¶ï¼Œç®€åŒ–äº† Docker çš„ä½¿ç”¨ï¼š

```bash
# åŸºç¡€ä½¿ç”¨
$ docker-compose run --rm deep-researcher

# è‡ªå®šä¹‰ç ”ç©¶ä¸»é¢˜
$ RESEARCH_TOPIC="é‡å­è®¡ç®—æœ€æ–°è¿›å±•" docker-compose run --rm deep-researcher

# è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶
$ RESEARCH_TOPIC="åŒºå—é“¾æŠ€æœ¯" OUTPUT_FILE="blockchain_research.md" docker-compose run --rm deep-researcher

# ä½¿ç”¨ OpenAI
$ LLM_PROVIDER=openai OPENAI_API_KEY=your_key RESEARCH_TOPIC="AI trends" docker-compose run --rm deep-researcher

# ä½¿ç”¨ Tavily æœç´¢
$ SEARCH_API=tavily TAVILY_API_KEY=your_key RESEARCH_TOPIC="Machine learning" docker-compose run --rm deep-researcher
```

### Docker ç¯å¢ƒå˜é‡

Docker å®¹å™¨æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
# LLM é…ç½®
LLM_PROVIDER=ollama                    # æˆ– openai
LOCAL_LLM=llama3                       # æ¨¡å‹åç§°
OLLAMA_BASE_URL=http://host.docker.internal:11434/ # Ollama æœåŠ¡åœ°å€
OPENAI_API_KEY=your_openai_api_key     # OpenAI API å¯†é’¥

# æœç´¢é…ç½®
SEARCH_API=duckduckgo                  # æœç´¢å¼•æ“é€‰æ‹©
TAVILY_API_KEY=your_tavily_key         # Tavily API å¯†é’¥
PERPLEXITY_API_KEY=your_perplexity_key # Perplexity API å¯†é’¥

# ç ”ç©¶é…ç½®
MAX_WEB_RESEARCH_LOOPS=3               # ç ”ç©¶å¾ªç¯æ¬¡æ•°
RESEARCH_TOPIC=äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿         # é»˜è®¤ç ”ç©¶ä¸»é¢˜
OUTPUT_FILE=research_report.md         # é»˜è®¤è¾“å‡ºæ–‡ä»¶å

# é«˜çº§é€‰é¡¹
USE_TOOL_CALLING=false                 # ä½¿ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼
STRIP_THINKING_TOKENS=true             # å»é™¤æ€ç»´ä»¤ç‰Œ
```

## ğŸ”§ é«˜çº§é…ç½®

### ç¯å¢ƒå˜é‡

é¡¹ç›®æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡è¿›è¡Œé…ç½®ï¼š

```shell
# LLM é…ç½®
LLM_PROVIDER=ollama                    # æˆ– openai
LOCAL_LLM=llama3                       # æ¨¡å‹åç§°
OLLAMA_BASE_URL=http://localhost:11434 # Ollama æœåŠ¡åœ°å€
OPENAI_BASE_URL=https://api.openai.com/v1 # OpenAI API åœ°å€

# æœç´¢é…ç½®
SEARCH_API=duckduckgo                  # æœç´¢å¼•æ“é€‰æ‹©
TAVILY_API_KEY=your_tavily_key         # Tavily API å¯†é’¥
PERPLEXITY_API_KEY=your_perplexity_key # Perplexity API å¯†é’¥
SEARXNG_URL=http://localhost:8888      # SearXNG æœåŠ¡åœ°å€

# ç ”ç©¶é…ç½®
MAX_WEB_RESEARCH_LOOPS=3               # æœ€å¤§ç ”ç©¶å¾ªç¯æ¬¡æ•°
FETCH_FULL_PAGE=true                   # æ˜¯å¦è·å–å®Œæ•´é¡µé¢å†…å®¹

# é«˜çº§é€‰é¡¹
USE_TOOL_CALLING=false                 # ä½¿ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼
STRIP_THINKING_TOKENS=true             # å»é™¤æ€ç»´ä»¤ç‰Œ
```

### æ”¯æŒçš„æ¨¡å‹

**Ollama æ¨¡å‹ï¼š**
- llama3, llama3.2
- deepseek-r1:8b, deepseek-r1:1.5b
- qwen2.5, codellama
- å…¶ä»–å…¼å®¹ Ollama çš„æ¨¡å‹

**OpenAI å…¼å®¹æ¨¡å‹ï¼š**
- gpt-4, gpt-3.5-turbo
- ä»»ä½• OpenAI å…¼å®¹ API çš„æ¨¡å‹

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### ğŸ”§ åŸºç¡€ç ”ç©¶æ¨¡å¼ç¤ºä¾‹

#### åŸºç¡€ä½¿ç”¨
```bash
# ä½¿ç”¨é»˜è®¤è®¾ç½®ç ”ç©¶äººå·¥æ™ºèƒ½è¶‹åŠ¿
python -m Langgraph_deep_researcher --topic "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿" --out ai_trends.md
```

#### é«˜çº§é…ç½®
```bash
# ä½¿ç”¨ Ollama + DeepSeek R1 è¿›è¡Œæ·±åº¦ç ”ç©¶
python -m Langgraph_deep_researcher \
  --topic "é‡å­è®¡ç®—æœ€æ–°è¿›å±•" \
  --out quantum_computing.md \
  --provider ollama \
  --model deepseek-r1:8b \
  --loops 5 \
  --search tavily \
  --tool-calling
```

### ğŸ—ï¸ ä¸»ç®¡æ¶æ„æ¨¡å¼ç¤ºä¾‹

#### åŸºç¡€ç ”ç©¶
```bash
# ä½¿ç”¨ä¸»ç®¡æ¶æ„è¿›è¡Œå¤æ‚ç ”ç©¶
python -m Langgraph_deep_researcher.supervisory_cli "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"
```

#### é«˜çº§é…ç½®
```bash
# ä½¿ç”¨ OpenAI + GPT-4 è¿›è¡Œæ·±åº¦åˆ†æ
python -m Langgraph_deep_researcher.supervisory_cli \
  "é‡å­è®¡ç®—æœ€æ–°è¿›å±•" \
  --out quantum_report.md \
  --provider openai \
  --model gpt-4 \
  --search-api tavily \
  --max-loops 5 \
  --verbose
```

#### æœ¬åœ°æ¨¡å‹ç ”ç©¶
```bash
# ä½¿ç”¨ Ollama + Llama3 è¿›è¡Œæœ¬åœ°ç ”ç©¶
python -m Langgraph_deep_researcher.supervisory_cli \
  "åŒºå—é“¾æŠ€æœ¯åº”ç”¨" \
  --provider ollama \
  --model llama3 \
  --search-api duckduckgo \
  --max-loops 3
```

### Docker ä½¿ç”¨

#### ğŸ”§ åŸºç¡€ç ”ç©¶æ¨¡å¼ Docker

```bash
# æ„å»ºå¹¶è¿è¡Œ Docker å®¹å™¨
docker build -t local-deep-researcher .
docker run --rm -v $(pwd):/app/output \
  -e LLM_PROVIDER=ollama \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  -e LOCAL_LLM=llama3 \
  local-deep-researcher \
  --topic "åŒºå—é“¾æŠ€æœ¯åº”ç”¨" \
  --out /app/output/blockchain_research.md
```

#### ğŸ—ï¸ ä¸»ç®¡æ¶æ„æ¨¡å¼ Docker

```bash
# ä½¿ç”¨ä¸»ç®¡æ¶æ„ Docker Compose
docker-compose -f docker-compose-supervisory.yml run --rm supervisory-researcher

# è‡ªå®šä¹‰ç ”ç©¶ä¸»é¢˜
RESEARCH_TOPIC="äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿" docker-compose -f docker-compose-supervisory.yml run --rm supervisory-researcher

# è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶
RESEARCH_TOPIC="é‡å­è®¡ç®—" OUTPUT_FILE="quantum_research.md" docker-compose -f docker-compose-supervisory.yml run --rm supervisory-researcher
```

### ä½¿ç”¨ä¾¿æ·è„šæœ¬

é¡¹ç›®åŒ…å«ä¾¿æ·è„šæœ¬ç®€åŒ– Docker ä½¿ç”¨ï¼š

**Linux/macOS:**
```bash
# åŸºç¡€ç ”ç©¶æ¨¡å¼
./docker-run.sh "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"

# ä¸»ç®¡æ¶æ„æ¨¡å¼
./docker-run-supervisory.sh "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"
```

**Windows:**
```cmd
REM åŸºç¡€ç ”ç©¶æ¨¡å¼
docker-run.bat "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"

REM ä¸»ç®¡æ¶æ„æ¨¡å¼
docker-run-supervisory.bat "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### ğŸ”§ åŸºç¡€ç ”ç©¶æ¨¡å¼é—®é¢˜

1. **æ¨¡å‹æ— æ³•ç”Ÿæˆ JSON è¾“å‡º**
   - è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ `--tool-calling` é€‰é¡¹
   - åŸå› ï¼šæŸäº›æ¨¡å‹ï¼ˆå¦‚ DeepSeek R1ï¼‰åœ¨ JSON æ¨¡å¼ä¸‹è¡¨ç°ä¸ä½³

2. **æœç´¢ API å¯†é’¥é”™è¯¯**
   - æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
   - ç¡®è®¤ API å¯†é’¥æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿé…é¢

3. **Ollama è¿æ¥å¤±è´¥**
   - ç¡®è®¤ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
   - æ£€æŸ¥ `OLLAMA_BASE_URL` æ˜¯å¦æ­£ç¡®

4. **å†…å­˜ä¸è¶³**
   - å‡å°‘ `MAX_WEB_RESEARCH_LOOPS` å€¼
   - ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
   - ç¦ç”¨ `FETCH_FULL_PAGE` é€‰é¡¹

#### ğŸ—ï¸ ä¸»ç®¡æ¶æ„æ¨¡å¼é—®é¢˜

1. **Agent åä½œå¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - éªŒè¯æœç´¢å¼•æ“ API é…ç½®
   - æŸ¥çœ‹è¯¦ç»†æ—¥å¿— (`--verbose` å‚æ•°)

2. **ä»»åŠ¡åˆ†è§£å¼‚å¸¸**
   - ç¡®è®¤æ¨¡å‹æ”¯æŒå¤æ‚æ¨ç†
   - å°è¯•ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰
   - æ£€æŸ¥è¾“å…¥ä¸»é¢˜æ˜¯å¦è¿‡äºå¤æ‚

3. **çŠ¶æ€ç®¡ç†é”™è¯¯**
   - é‡å¯åº”ç”¨ç¨‹åº
   - æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
   - æŸ¥çœ‹ Docker æ—¥å¿—ï¼ˆå¦‚æœä½¿ç”¨ Dockerï¼‰

### è°ƒè¯•æ¨¡å¼

#### åŸºç¡€ç ”ç©¶æ¨¡å¼
```bash
python -m Langgraph_deep_researcher --topic "æµ‹è¯•ä¸»é¢˜" --out test.md --loops 1
```

#### ä¸»ç®¡æ¶æ„æ¨¡å¼
```bash
python -m Langgraph_deep_researcher.supervisory_cli "æµ‹è¯•ä¸»é¢˜" --verbose
```

#### Docker è°ƒè¯•
```bash
# æŸ¥çœ‹åŸºç¡€ç ”ç©¶æ¨¡å¼æ—¥å¿—
docker-compose logs deep-researcher

# æŸ¥çœ‹ä¸»ç®¡æ¶æ„æ¨¡å¼æ—¥å¿—
docker-compose -f docker-compose-supervisory.yml logs supervisory-researcher
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æ­¤ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“Š ç ”ç©¶æŠ¥å‘Šç¤ºä¾‹

### åŸºç¡€ç ”ç©¶æ¨¡å¼æŠ¥å‘Š
- **[AIå‘å±•è¶‹åŠ¿ç ”ç©¶æŠ¥å‘Š](ai_trends.md)** - ä½¿ç”¨åŸºç¡€ç ”ç©¶æ¨¡å¼ç”Ÿæˆçš„AIå‘å±•è¶‹åŠ¿æ·±åº¦åˆ†ææŠ¥å‘Š

### ä¸»ç®¡æ¶æ„æ¨¡å¼æŠ¥å‘Š  
- **[ä¸»ç®¡æ¶æ„ç ”ç©¶æŠ¥å‘Š](supervisory_research_report.md)** - ä½¿ç”¨ä¸»ç®¡æ¶æ„æ¨¡å¼ç”Ÿæˆçš„äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿å¤šç»´åº¦åˆ†ææŠ¥å‘Š

è¿™äº›æŠ¥å‘Šå±•ç¤ºäº†ä¸¤ç§ç ”ç©¶æ¨¡å¼çš„ä¸åŒç‰¹ç‚¹å’Œè¾“å‡ºè´¨é‡ï¼Œå¯ä»¥ä½œä¸ºä½¿ç”¨å‚è€ƒã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº Apache 2.0 è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

