# Local Deep Researcher

Local Deep Researcher æ˜¯ä¸€ä¸ªå®Œå…¨æœ¬åœ°åŒ–çš„ç½‘ç»œç ”ç©¶åŠ©æ‰‹ï¼Œæ”¯æŒä½¿ç”¨ [Ollama](https://ollama.com/search) æˆ– [OpenAI](https://openai.com/) æ‰˜ç®¡çš„ä»»ä½• LLMã€‚ç»™å®ƒä¸€ä¸ªä¸»é¢˜ï¼Œå®ƒä¼šç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢ã€æ”¶é›†æœç´¢ç»“æœã€æ€»ç»“æœç´¢ç»“æœã€åæ€æ‘˜è¦ä»¥æ£€æŸ¥çŸ¥è¯†ç¼ºå£ã€ç”Ÿæˆæ–°çš„æœç´¢æŸ¥è¯¢æ¥è§£å†³è¿™äº›ç¼ºå£ï¼Œå¹¶é‡å¤ç”¨æˆ·å®šä¹‰æ¬¡æ•°çš„å¾ªç¯ã€‚å®ƒå°†ä¸ºç”¨æˆ·æä¾›åŒ…å«æ‰€æœ‰ç”¨äºç”Ÿæˆæ‘˜è¦çš„æ¥æºçš„æœ€ç»ˆ Markdown æ‘˜è¦ã€‚

![Langgraph-deep-research](https://github.com/user-attachments/assets/1c6b28f8-6b64-42ba-a491-1ab2875d50ea)




## ğŸš€ å¿«é€Ÿå¼€å§‹

å…‹éš†ä»“åº“ï¼š
```shell
git clone https://github.com/langchain-ai/local-deep-researcher.git
cd local-deep-researcher
```

ç„¶åæ ¹æ®æ‚¨çš„éœ€è¦ç¼–è¾‘ `.env` æ–‡ä»¶æ¥è‡ªå®šä¹‰ç¯å¢ƒå˜é‡ã€‚è¿™äº›ç¯å¢ƒå˜é‡æ§åˆ¶æ¨¡å‹é€‰æ‹©ã€æœç´¢å·¥å…·å’Œå…¶ä»–é…ç½®è®¾ç½®ã€‚å½“æ‚¨è¿è¡Œåº”ç”¨ç¨‹åºæ—¶ï¼Œè¿™äº›å€¼å°†é€šè¿‡ `python-dotenv` è‡ªåŠ¨åŠ è½½ã€‚
```shell
cp .env.example .env
```

### ä½¿ç”¨ Ollama é€‰æ‹©æœ¬åœ°æ¨¡å‹

1. ä» [è¿™é‡Œ](https://ollama.com/download) ä¸‹è½½ Ollama åº”ç”¨ã€‚

2. ä» [Ollama](https://ollama.com/search) æ‹‰å–æœ¬åœ° LLMã€‚ä»¥ [DeepSeek R1](https://ollama.com/library/deepseek-r1:8b) ä¸ºä¾‹ï¼š
```shell
ollama pull deepseek-r1:8b
```

3. å¯é€‰åœ°ï¼Œä½¿ç”¨ä»¥ä¸‹ Ollama é…ç½®è®¾ç½®æ›´æ–° `.env` æ–‡ä»¶ã€‚

* å¦‚æœè®¾ç½®äº†è¿™äº›å€¼ï¼Œå®ƒä»¬å°†ä¼˜å…ˆäº `configuration.py` ä¸­ `Configuration` ç±»è®¾ç½®çš„é»˜è®¤å€¼ã€‚
```shell
LLM_PROVIDER=ollama
OLLAMA_BASE_URL="http://localhost:11434" # Ollama æœåŠ¡ç«¯ç‚¹ï¼Œé»˜è®¤ä¸º `http://localhost:11434`
LOCAL_LLM=model # è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¦‚æœæœªè®¾ç½®åˆ™é»˜è®¤ä¸º `llama3`
```

### é€‰æ‹©æœç´¢å·¥å…·

é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†ä½¿ç”¨ [DuckDuckGo](https://duckduckgo.com/) è¿›è¡Œç½‘ç»œæœç´¢ï¼Œæ— éœ€ API å¯†é’¥ã€‚ä½†æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡å°† API å¯†é’¥æ·»åŠ åˆ°ç¯å¢ƒæ–‡ä»¶ä¸­æ¥ä½¿ç”¨ [SearXNG](https://docs.searxng.org/)ã€[Tavily](https://tavily.com/) æˆ– [Perplexity](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api)ã€‚å¯é€‰åœ°ï¼Œä½¿ç”¨ä»¥ä¸‹æœç´¢å·¥å…·é…ç½®å’Œ API å¯†é’¥æ›´æ–° `.env` æ–‡ä»¶ã€‚å¦‚æœè®¾ç½®äº†è¿™äº›å€¼ï¼Œå®ƒä»¬å°†ä¼˜å…ˆäº `configuration.py` ä¸­ `Configuration` ç±»è®¾ç½®çš„é»˜è®¤å€¼ã€‚
```shell
SEARCH_API=xxx # è¦ä½¿ç”¨çš„æœç´¢ APIï¼Œå¦‚ `duckduckgo`ï¼ˆé»˜è®¤ï¼‰
TAVILY_API_KEY=xxx # è¦ä½¿ç”¨çš„ tavily API å¯†é’¥
PERPLEXITY_API_KEY=xxx # è¦ä½¿ç”¨çš„ perplexity API å¯†é’¥
MAX_WEB_RESEARCH_LOOPS=xxx # ç ”ç©¶å¾ªç¯æ­¥éª¤çš„æœ€å¤§æ•°é‡ï¼Œé»˜è®¤ä¸º `3`
FETCH_FULL_PAGE=xxx # è·å–å®Œæ•´é¡µé¢å†…å®¹ï¼ˆä½¿ç”¨ `duckduckgo` æ—¶ï¼‰ï¼Œé»˜è®¤ä¸º `true`
USE_TOOL_CALLING=xxx # ä½¿ç”¨å·¥å…·è°ƒç”¨è€Œä¸æ˜¯ JSON æ¨¡å¼ï¼Œé»˜è®¤ä¸º `false`
STRIP_THINKING_TOKENS=xxx # ä»æ¨¡å‹å“åº”ä¸­å»é™¤ <think> ä»¤ç‰Œï¼Œé»˜è®¤ä¸º `true`
```

### ä»ç»ˆç«¯è¿è¡Œ

#### Mac/Linux

1. ï¼ˆæ¨èï¼‰åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š
```bash
python -m venv .venv
source .venv/bin/activate
```

2. å®‰è£…ä¾èµ–å¹¶è¿è¡Œï¼š

```bash
# å®‰è£…ä¾èµ–
pip install -e .

# è¿è¡Œç ”ç©¶åŠ©æ‰‹
python -m Langgraph_deep_researcher --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" --out research_report.md
```

#### Windows

1. ï¼ˆæ¨èï¼‰åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

* å®‰è£… `Python 3.11`ï¼ˆå¹¶åœ¨å®‰è£…è¿‡ç¨‹ä¸­æ·»åŠ åˆ° PATHï¼‰ã€‚
* é‡å¯ç»ˆç«¯ä»¥ç¡®ä¿ Python å¯ç”¨ï¼Œç„¶ååˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

2. å®‰è£…ä¾èµ–å¹¶è¿è¡Œï¼š

```powershell
# å®‰è£…ä¾èµ–
pip install -e .

# è¿è¡Œç ”ç©¶åŠ©æ‰‹
python -m Langgraph_deep_researcher --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" --out research_report.md
```

### å‘½ä»¤è¡Œä½¿ç”¨

æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æ¥è‡ªå®šä¹‰ç ”ç©¶ï¼š

```bash
python -m Langgraph_deep_researcher --topic "äººå·¥æ™ºèƒ½è¶‹åŠ¿" --out ai_trends.md --provider ollama --model llama3 --loops 5
```

å¯ç”¨é€‰é¡¹ï¼š
- `--topic`: ç ”ç©¶ä¸»é¢˜ï¼ˆå¿…éœ€ï¼‰
- `--out`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `--provider`: åœ¨ "ollama" æˆ– "openai" ä¹‹é—´é€‰æ‹©
- `--model`: æŒ‡å®šæ¨¡å‹åç§°ï¼ˆå¦‚ "llama3", "gpt-4"ï¼‰
- `--loops`: ç ”ç©¶è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰
- `--search`: è¦ä½¿ç”¨çš„æœç´¢ APIï¼ˆ"duckduckgo", "tavily", "perplexity", "searxng"ï¼‰
- `--tool-calling`: ä½¿ç”¨å·¥å…·è°ƒç”¨è€Œä¸æ˜¯ JSON æ¨¡å¼
- `--no-strip-think`: ä¸ä»æ¨¡å‹å“åº”ä¸­å»é™¤ <think> ä»¤ç‰Œ

### æ¨¡å‹å…¼å®¹æ€§è¯´æ˜

é€‰æ‹©æœ¬åœ° LLM æ—¶ï¼ŒæŸäº›æ­¥éª¤ä½¿ç”¨ç»“æ„åŒ– JSON è¾“å‡ºã€‚ä¸€äº›æ¨¡å‹å¯èƒ½éš¾ä»¥æ»¡è¶³æ­¤è¦æ±‚ï¼ŒåŠ©æ‰‹å…·æœ‰å›é€€æœºåˆ¶æ¥å¤„ç†è¿™ç§æƒ…å†µã€‚ä¾‹å¦‚ï¼Œ[DeepSeek R1 (7B)](https://ollama.com/library/deepseek-llm:7b) å’Œ [DeepSeek R1 (1.5B)](https://ollama.com/library/deepseek-r1:1.5b) æ¨¡å‹éš¾ä»¥ç”Ÿæˆæ‰€éœ€çš„ JSON è¾“å‡ºï¼ŒåŠ©æ‰‹å°†ä½¿ç”¨å›é€€æœºåˆ¶æ¥å¤„ç†è¿™ç§æƒ…å†µã€‚

å¯¹äºè¿™äº›æ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨ `--tool-calling` é€‰é¡¹æ¥å¯ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼ï¼Œè¿™é€šå¸¸æ¯” JSON æ¨¡å¼æ›´å¯é ã€‚
  

## å·¥ä½œåŸç†

Local Deep Researcher å—åˆ° [IterDRAG](https://arxiv.org/html/2410.04343v1#:~:text=To%20tackle%20this%20issue%2C%20we,used%20to%20generate%20intermediate%20answers.) çš„å¯å‘ã€‚è¿™ç§æ–¹æ³•å°†æŸ¥è¯¢åˆ†è§£ä¸ºå­æŸ¥è¯¢ï¼Œä¸ºæ¯ä¸ªå­æŸ¥è¯¢æ£€ç´¢æ–‡æ¡£ï¼Œå›ç­”å­æŸ¥è¯¢ï¼Œç„¶åé€šè¿‡ä¸ºç¬¬äºŒä¸ªå­æŸ¥è¯¢æ£€ç´¢æ–‡æ¡£æ¥æ„å»ºç­”æ¡ˆã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åšç±»ä¼¼çš„äº‹æƒ…ï¼š

1. **ç”Ÿæˆæœç´¢æŸ¥è¯¢** - ç»™å®šç”¨æˆ·æä¾›çš„ä¸»é¢˜ï¼Œä½¿ç”¨æœ¬åœ° LLMï¼ˆé€šè¿‡ [Ollama](https://ollama.com/search) æˆ– [OpenAI](https://openai.com/)ï¼‰ç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢
2. **æ‰§è¡Œç½‘ç»œæœç´¢** - ä½¿ç”¨æœç´¢å¼•æ“/å·¥å…·æ‰¾åˆ°ç›¸å…³æ¥æº
3. **æ€»ç»“å‘ç°** - ä½¿ç”¨ LLM æ€»ç»“ä¸ç”¨æˆ·æä¾›çš„ç ”ç©¶ä¸»é¢˜ç›¸å…³çš„ç½‘ç»œæœç´¢ç»“æœ
4. **åæ€æ‘˜è¦** - ç„¶åä½¿ç”¨ LLM åæ€æ‘˜è¦ï¼Œè¯†åˆ«çŸ¥è¯†ç¼ºå£
5. **ç”Ÿæˆåç»­æŸ¥è¯¢** - ç”Ÿæˆæ–°çš„æœç´¢æŸ¥è¯¢æ¥è§£å†³çŸ¥è¯†ç¼ºå£
6. **è¿­ä»£æ›´æ–°** - è¿‡ç¨‹é‡å¤ï¼Œæ‘˜è¦é€šè¿‡æ¥è‡ªç½‘ç»œæœç´¢çš„æ–°ä¿¡æ¯è¿›è¡Œè¿­ä»£æ›´æ–°
7. **å¯é…ç½®å¾ªç¯** - è¿è¡Œå¯é…ç½®æ¬¡æ•°çš„è¿­ä»£ï¼ˆå‚è§é…ç½®éƒ¨åˆ†ï¼‰

## è¾“å‡ºç»“æœ

ç ”ç©¶åŠ©æ‰‹ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„ç»¼åˆ Markdown æŠ¥å‘Šï¼š

- **ç ”ç©¶æ‘˜è¦**ï¼šå¯¹æ‚¨ä¸»é¢˜çš„è¯¦ç»†åˆ†æ
- **ä¿¡æ¯æ¥æº**ï¼šç ”ç©¶ä¸­ä½¿ç”¨çš„æ‰€æœ‰ç½‘ç»œæ¥æºï¼Œå¸¦æœ‰é€‚å½“çš„å¼•ç”¨
- **ç ”ç©¶è¿‡ç¨‹**ï¼šæœ‰å…³ä½¿ç”¨çš„è¿­ä»£ç ”ç©¶æ–¹æ³•çš„ä¿¡æ¯

æœ€ç»ˆæŠ¥å‘Šä¿å­˜ä¸º Markdown æ–‡ä»¶ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹ã€å…±äº«æˆ–è¿›ä¸€æ­¥å¤„ç†ã€‚


## ä½œä¸º Docker å®¹å™¨è¿è¡Œ

åŒ…å«çš„ `Dockerfile` å°†ç ”ç©¶åŠ©æ‰‹ä½œä¸ºå‘½ä»¤è¡Œå·¥å…·è¿è¡Œã€‚æ‚¨å¿…é¡»å•ç‹¬è¿è¡Œ Ollama å¹¶é…ç½® `OLLAMA_BASE_URL` ç¯å¢ƒå˜é‡ã€‚æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡æä¾› `LOCAL_LLM` ç¯å¢ƒå˜é‡æ¥æŒ‡å®šè¦ä½¿ç”¨çš„ Ollama æ¨¡å‹ã€‚

### åŸºç¡€ Docker ä½¿ç”¨

å…‹éš†ä»“åº“å¹¶æ„å»ºé•œåƒï¼š
```bash
$ docker build -t local-deep-researcher .
```

ä½¿ç”¨ç ”ç©¶ä¸»é¢˜è¿è¡Œå®¹å™¨ï¼š
```bash
$ docker run --rm -it \
  -e LLM_PROVIDER=ollama \
  -e OLLAMA_BASE_URL="http://host.docker.internal:11434/" \
  -e LOCAL_LLM="llama3" \
  -v $(pwd)/output:/app/output \
  local-deep-researcher \
  --topic "æ‚¨çš„ç ”ç©¶ä¸»é¢˜" \
  --out "/app/output/research_report.md"
```

### ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

é¡¹ç›®åŒ…å« `docker-compose.yml` æ–‡ä»¶ï¼Œç®€åŒ–äº† Docker çš„ä½¿ç”¨ï¼š

```bash
# åŸºç¡€ä½¿ç”¨
$ docker-compose run --rm deep-researcher

# è‡ªå®šä¹‰ç ”ç©¶ä¸»é¢˜
$ RESEARCH_TOPIC="é‡å­è®¡ç®—æœ€æ–°è¿›å±•" docker-compose run --rm deep-researcher

# è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶
$ RESEARCH_TOPIC="åŒºå—é“¾æŠ€æœ¯" OUTPUT_FILE="blockchain_research.md" docker-compose run --rm deep-researcher

# ä½¿ç”¨ OpenAI
$ LLM_PROVIDER=openai OPENAI_API_KEY=your_key RESEARCH_TOPIC="AI trends" docker-compose run --rm deep-researcher

# ä½¿ç”¨ Tavily æœç´¢
$ SEARCH_API=tavily TAVILY_API_KEY=your_key RESEARCH_TOPIC="Machine learning" docker-compose run --rm deep-researcher
```

### Docker ç¯å¢ƒå˜é‡

Docker å®¹å™¨æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
# LLM é…ç½®
LLM_PROVIDER=ollama                    # æˆ– openai
LOCAL_LLM=llama3                       # æ¨¡å‹åç§°
OLLAMA_BASE_URL=http://host.docker.internal:11434/ # Ollama æœåŠ¡åœ°å€
OPENAI_API_KEY=your_openai_api_key     # OpenAI API å¯†é’¥

# æœç´¢é…ç½®
SEARCH_API=duckduckgo                  # æœç´¢å¼•æ“é€‰æ‹©
TAVILY_API_KEY=your_tavily_key         # Tavily API å¯†é’¥
PERPLEXITY_API_KEY=your_perplexity_key # Perplexity API å¯†é’¥

# ç ”ç©¶é…ç½®
MAX_WEB_RESEARCH_LOOPS=3               # ç ”ç©¶å¾ªç¯æ¬¡æ•°
RESEARCH_TOPIC=äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿         # é»˜è®¤ç ”ç©¶ä¸»é¢˜
OUTPUT_FILE=research_report.md         # é»˜è®¤è¾“å‡ºæ–‡ä»¶å

# é«˜çº§é€‰é¡¹
USE_TOOL_CALLING=false                 # ä½¿ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼
STRIP_THINKING_TOKENS=true             # å»é™¤æ€ç»´ä»¤ç‰Œ
```

## ğŸ”§ é«˜çº§é…ç½®

### ç¯å¢ƒå˜é‡

é¡¹ç›®æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡è¿›è¡Œé…ç½®ï¼š

```shell
# LLM é…ç½®
LLM_PROVIDER=ollama                    # æˆ– openai
LOCAL_LLM=llama3                       # æ¨¡å‹åç§°
OLLAMA_BASE_URL=http://localhost:11434 # Ollama æœåŠ¡åœ°å€
OPENAI_BASE_URL=https://api.openai.com/v1 # OpenAI API åœ°å€

# æœç´¢é…ç½®
SEARCH_API=duckduckgo                  # æœç´¢å¼•æ“é€‰æ‹©
TAVILY_API_KEY=your_tavily_key         # Tavily API å¯†é’¥
PERPLEXITY_API_KEY=your_perplexity_key # Perplexity API å¯†é’¥
SEARXNG_URL=http://localhost:8888      # SearXNG æœåŠ¡åœ°å€

# ç ”ç©¶é…ç½®
MAX_WEB_RESEARCH_LOOPS=3               # æœ€å¤§ç ”ç©¶å¾ªç¯æ¬¡æ•°
FETCH_FULL_PAGE=true                   # æ˜¯å¦è·å–å®Œæ•´é¡µé¢å†…å®¹

# é«˜çº§é€‰é¡¹
USE_TOOL_CALLING=false                 # ä½¿ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼
STRIP_THINKING_TOKENS=true             # å»é™¤æ€ç»´ä»¤ç‰Œ
```

### æ”¯æŒçš„æ¨¡å‹

**Ollama æ¨¡å‹ï¼š**
- llama3, llama3.2
- deepseek-r1:8b, deepseek-r1:1.5b
- qwen2.5, codellama
- å…¶ä»–å…¼å®¹ Ollama çš„æ¨¡å‹

**OpenAI å…¼å®¹æ¨¡å‹ï¼š**
- gpt-4, gpt-3.5-turbo
- ä»»ä½• OpenAI å…¼å®¹ API çš„æ¨¡å‹

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨
```bash
# ä½¿ç”¨é»˜è®¤è®¾ç½®ç ”ç©¶äººå·¥æ™ºèƒ½è¶‹åŠ¿
python -m Langgraph_deep_researcher --topic "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿" --out ai_trends.md
```

### é«˜çº§ä½¿ç”¨
```bash
# ä½¿ç”¨ Ollama + DeepSeek R1 è¿›è¡Œæ·±åº¦ç ”ç©¶
python -m Langgraph_deep_researcher \
  --topic "é‡å­è®¡ç®—æœ€æ–°è¿›å±•" \
  --out quantum_computing.md \
  --provider ollama \
  --model deepseek-r1:8b \
  --loops 5 \
  --search tavily \
  --tool-calling
```

### Docker ä½¿ç”¨
```bash
# æ„å»ºå¹¶è¿è¡Œ Docker å®¹å™¨
docker build -t local-deep-researcher .
docker run --rm -v $(pwd):/app/output \
  -e LLM_PROVIDER=ollama \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  -e LOCAL_LLM=llama3 \
  local-deep-researcher \
  --topic "åŒºå—é“¾æŠ€æœ¯åº”ç”¨" \
  --out /app/output/blockchain_research.md
```

### ä½¿ç”¨ä¾¿æ·è„šæœ¬

é¡¹ç›®åŒ…å«ä¾¿æ·è„šæœ¬ç®€åŒ– Docker ä½¿ç”¨ï¼š

**Linux/macOS:**
```bash
# åŸºç¡€ä½¿ç”¨
./docker-run.sh "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"

# è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶
./docker-run.sh "é‡å­è®¡ç®—" quantum_research.md

# ä½¿ç”¨ç¯å¢ƒå˜é‡
RESEARCH_TOPIC="AIè¶‹åŠ¿" LLM_PROVIDER=openai ./docker-run.sh
```

**Windows:**
```cmd
REM åŸºç¡€ä½¿ç”¨
docker-run.bat "æ‚¨çš„ç ”ç©¶ä¸»é¢˜"

REM è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶
docker-run.bat "é‡å­è®¡ç®—" quantum_research.md

REM ä½¿ç”¨ç¯å¢ƒå˜é‡
set RESEARCH_TOPIC=AIè¶‹åŠ¿
set LLM_PROVIDER=openai
docker-run.bat
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹æ— æ³•ç”Ÿæˆ JSON è¾“å‡º**
   - è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ `--tool-calling` é€‰é¡¹
   - åŸå› ï¼šæŸäº›æ¨¡å‹ï¼ˆå¦‚ DeepSeek R1ï¼‰åœ¨ JSON æ¨¡å¼ä¸‹è¡¨ç°ä¸ä½³

2. **æœç´¢ API å¯†é’¥é”™è¯¯**
   - æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
   - ç¡®è®¤ API å¯†é’¥æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿé…é¢

3. **Ollama è¿æ¥å¤±è´¥**
   - ç¡®è®¤ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
   - æ£€æŸ¥ `OLLAMA_BASE_URL` æ˜¯å¦æ­£ç¡®

4. **å†…å­˜ä¸è¶³**
   - å‡å°‘ `MAX_WEB_RESEARCH_LOOPS` å€¼
   - ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
   - ç¦ç”¨ `FETCH_FULL_PAGE` é€‰é¡¹

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡ºï¼š
```bash
python -m Langgraph_deep_researcher --topic "æµ‹è¯•ä¸»é¢˜" --out test.md --loops 1
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æ­¤ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [LangChain](https://github.com/langchain-ai/langchain) - LLM åº”ç”¨æ¡†æ¶
- [LangGraph](https://github.com/langchain-ai/langgraph) - çŠ¶æ€å›¾æ„å»ºå·¥å…·
- [Ollama](https://ollama.com/) - æœ¬åœ° LLM éƒ¨ç½²
- [IterDRAG](https://arxiv.org/html/2410.04343v1) - ç ”ç©¶çµæ„Ÿæ¥æº

